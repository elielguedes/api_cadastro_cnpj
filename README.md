# API Cadastro CNPJ - FastAPI

## Descri√ß√£o
API RESTful para cadastro, consulta e gest√£o de empresas brasileiras (CNPJ), utilizando dados p√∫blicos do portal dados.gov.br. Desenvolvida com FastAPI, SQLAlchemy com suporte completo a PostgreSQL e fallback SQLite.

## üöÄ Funcionalidades
- ‚úÖ CRUD completo para empresas, estabelecimentos e s√≥cios
- ‚úÖ Sistema de Tags com relacionamento N:N
- ‚úÖ Filtros avan√ßados, ordena√ß√£o e pagina√ß√£o
- ‚úÖ Autentica√ß√£o JWT com controle de permiss√µes (admin/leitor)
- ‚úÖ Documenta√ß√£o autom√°tica interativa (Swagger/OpenAPI)
- ‚úÖ Valida√ß√£o de CNPJ integrada
- ‚úÖ Import/Export de dados CSV
- ‚úÖ Migrations com Alembic
- ‚úÖ Testes automatizados
- ‚úÖ Dockerizado com PostgreSQL
- ‚úÖ Deploy pronto para AWS EC2

## üèÉ‚Äç‚ôÇÔ∏è In√≠cio R√°pido

### Local (Recomendado)
```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/elielguedes/Relatorio_Eliel_Guedes.git
cd Relatorio_Eliel_Guedes/framework_udf

# 2. Crie e ative ambiente virtual (Python 3.9+)
python -m venv .venv
# Windows
.\.venv\Scripts\Activate.ps1
# Linux/Mac
source .venv/bin/activate

# 3. Instale depend√™ncias
pip install -r requirements.txt

# 4. Inicie a aplica√ß√£o
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# 5. Acesse a documenta√ß√£o
# http://localhost:8000/docs
```

### Com Docker

**Desenvolvimento:**
```bash
# Desenvolvimento com hot-reload
docker-compose -f docker-compose.dev.yml up --build

# Acesse: http://localhost:8001/docs
```

**Produ√ß√£o:**
```bash
# Produ√ß√£o com PostgreSQL
docker-compose up --build

# Com Nginx (SSL/proxy)
docker-compose --profile production up --build

# Acesse: http://localhost:8000/docs
```

## Estrutura do Projeto
- `app/models/models.py`: Modelos ORM
- `app/schemas.py`: Schemas Pydantic
- `app/routers/`: Rotas da API
- `app/services/`: L√≥gica de neg√≥cio
- `app/auth.py`: Autentica√ß√£o JWT
- `data/repasse-s.csv`: Dados p√∫blicos

## Diagrama ER

```mermaid
erDiagram
    USUARIO ||--o{ EMPRESA : criou
    EMPRESA ||--o{ ESTABELECIMENTO : possui
    ESTABELECIMENTO ||--o{ SOCIO : possui
    EMPRESA }o--o{ TAG : rotulada_com

    USUARIO {
        int id
        string username
        bool is_admin
    }

    EMPRESA {
        int id
        string nome
        string cnpj
    }

    ESTABELECIMENTO {
        int id
        string nome
        int empresa_id
    }

    SOCIO {
        int id
        string nome
        int estabelecimento_id
    }

    TAG {
        int id
        string name
    }
```

## Origem dos Dados
- Fonte: [dados.gov.br](https://dados.gov.br)
- Formato: CSV
- Periodicidade: conforme atualiza√ß√£o oficial

## Relat√≥rio r√°pido / EDA

- Arquivo principal: `data/repasse-s.csv` (CSV delimitado por `;`).
- Colunas mapeadas para entidades: `Entidade` -> `Empresa.nome`, `UC/CNPJ` -> `Empresa.cnpj`.
- A carga inicial evita duplicatas por `nome`.
- Recomenda-se validar e normalizar CNPJ (remo√ß√£o de m√°scara) antes de inserir em produ√ß√£o.

## Scripts de importa√ß√£o / exporta√ß√£o

H√° scripts pr√°ticos no diret√≥rio `scripts/` para trabalhar com o CSV local:

- `scripts/import_repasse.py` ‚Äî importa `data/repasse-s.csv` para o DB validando CNPJ.
- `scripts/import_repasse_with_report.py` ‚Äî import com relat√≥rio de rejeitados em `data/import_rejeitados.csv`.
- `scripts/export_empresas.py` ‚Äî exporta as empresas atuais do DB para `data/empresas_importadas.csv`.

Uso (PowerShell/Bash, no venv):

```bash
# ativar venv
# Windows
.\.venv\Scripts\Activate.ps1
# Linux/Mac  
source .venv/bin/activate

# importar (simples)
python scripts/import_repasse.py

# importar com relat√≥rio (gera data/import_rejeitados.csv)
python scripts/import_repasse_with_report.py

# exportar empresas
python scripts/export_empresas.py
```

Op√ß√µes do `import_repasse_with_report.py`:

- `--dry-run` : processa o CSV e gera o relat√≥rio de rejeitados sem inserir nada no banco.
- `--limit N` : limita o n√∫mero de linhas processadas (√∫til para testes).
- `--out <path>` : caminho do arquivo de relat√≥rio de rejeitados (padr√£o: `data/import_rejeitados.csv`).

Exemplo (dry-run, 100 linhas):

```powershell
venv\Scripts\python.exe scripts\import_repasse_with_report.py --dry-run --limit 100
```

## Migrations (Alembic)

1. Instale alembic no venv:

```powershell
pip install alembic
```

2. Crie a primeira migration (autogenerate usa `app.database.Base`):

```powershell
alembic revision --autogenerate -m "initial"
alembic upgrade head
```

Observa√ß√£o: j√° existe um esqueleto `alembic/env.py` apontando para `app.database.Base`.

Nota importante sobre estados locais de banco:
- Se voc√™ j√° executou a aplica√ß√£o antes e as tabelas j√° existem (SQLite ou outro), o `alembic upgrade head` pode falhar porque as tabelas j√° existem. Nesse caso voc√™ pode:
    - Usar `alembic stamp head` para marcar a migration atual como aplicada sem tentar recriar tabelas (√∫til em dev local quando j√° existem dados).
    - Ou dropar o banco local (apenas em dev) e rodar `alembic upgrade head` novamente.

## Testes

1. Instale pytest e httpx:

```powershell
pip install pytest httpx
```

2. Execute os testes:

```powershell
pytest -q
```

Um teste b√°sico (autentica√ß√£o + CRUD de empresas) foi adicionado em `tests/test_auth_empresa.py`.

## üåê Deploy AWS EC2

Esta aplica√ß√£o est√° otimizada para deploy no Amazon EC2 com Amazon Linux 2023.

### Pr√©-requisitos EC2
- Inst√¢ncia EC2 (t3.micro ou superior)
- Security Groups: SSH(22), HTTP(80), HTTPS(443), Custom TCP(8000)
- Amazon Linux 2023 (Python 3.9+ nativo)

### Deploy Autom√°tico
```bash
# 1. Conectar ao EC2
ssh -i sua-chave.pem ec2-user@seu-ip

# 2. Clonar reposit√≥rio
git clone https://github.com/elielguedes/Relatorio_Eliel_Guedes.git
cd Relatorio_Eliel_Guedes/framework_udf

# 3. Executar script de deploy
chmod +x deploy/quick-deploy.sh
./deploy/quick-deploy.sh

# 4. Configurar produ√ß√£o (opcional)
sudo cp deploy/nginx.conf /etc/nginx/conf.d/fastapi.conf
sudo cp deploy/fastapi-app.service /etc/systemd/system/
sudo systemctl enable fastapi-app
sudo systemctl start fastapi-app
```

### Compatibilidade
‚úÖ **Python 3.9+** (compat√≠vel com Amazon Linux 2023)  
‚úÖ **SQLAlchemy 2.0** com fallback autom√°tico SQLite ‚Üí PostgreSQL  
‚úÖ **Pydantic v2** com configura√ß√£o otimizada  
‚úÖ **FastAPI 0.119+** com todas as features modernas  

## üß™ Testes

### Testes Automatizados
```bash
# Instalar depend√™ncias de teste
pip install pytest httpx

# Executar todos os testes
pytest -v

# Testes com cobertura
pytest --cov=app tests/
```

### Cole√ß√£o Postman
üìã **Cole√ß√£o completa dispon√≠vel**: `postman_collection_complete.json`

**Inclui:**
- ‚úÖ Autentica√ß√£o JWT (admin/leitor)
- ‚úÖ CRUD Empresas com filtros
- ‚úÖ CRUD Estabelecimentos  
- ‚úÖ CRUD S√≥cios
- ‚úÖ Sistema de Tags com associa√ß√µes
- ‚úÖ Vari√°veis de ambiente configuradas
- ‚úÖ Testes automatizados com scripts
- ‚úÖ Token management autom√°tico

**Como usar:**
1. Importe `postman_collection_complete.json` no Postman
2. Configure vari√°vel `base_url` (padr√£o: `http://localhost:8000`)
3. Execute "Login" para obter token automaticamente
4. Todos os endpoints estar√£o prontos para uso

## üìã Pr√≥ximos passos recomendados
- ‚úÖ Valida√ß√£o e normaliza√ß√£o de CNPJ implementada
- ‚úÖ Cole√ß√£o Postman atualizada
- ‚úÖ Deploy EC2 configurado
- ‚è≥ CI/CD GitHub Actions
- ‚è≥ Monitoramento e logs centralizados
- ‚è≥ Cache Redis para performance
- ‚è≥ Rate limiting e seguran√ßa avan√ßada

## Autores
- Eliel Guedes

## Licen√ßa
MIT

## Executando localmente (venv)

Este projeto pode ser executado localmente com um ambiente virtual Python.

1. Crie e ative o venv:

```powershell
python -m venv .\.venv
.\.venv\Scripts\Activate.ps1
```

2. Instale depend√™ncias:

```powershell
pip install -r requirements.txt
```

3. Inicie a aplica√ß√£o:

```powershell
venv\Scripts\python.exe -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Ou use o helper `start.ps1` que j√° configura o venv e roda o servidor:

```powershell
.\start.ps1
# ou para habilitar o carregamento autom√°tico do CSV
.\start.ps1 -AutoLoad
```

Se quiser rodar a aplica√ß√£o apontando para um PostgreSQL externo, exporte a vari√°vel de ambiente `DATABASE_URL`:

```powershell
$env:DATABASE_URL = "postgresql+psycopg2://user:pass@host:5432/dbname"
uvicorn app.main:app --reload

## Endpoints importantes (r√°pido resumo)

- Auth:
    - POST /auth/register ‚Äî registrar usu√°rio (retorna token)
    - POST /auth/login ‚Äî login (retorna access_token)

- Empresas:
    - GET /empresas/ ‚Äî lista (aceita skip/limit/nome/cnpj/order_by)
    - POST /empresas/ ‚Äî criar (admin)
    - GET /empresas/{id} ‚Äî detalhe (inclui `tags` via `EmpresaRead`)
    - PUT /empresas/{id} ‚Äî atualizar (admin)
    - DELETE /empresas/{id} ‚Äî remover (admin)

- Tags:
    - GET /tags/ ‚Äî lista tags
    - POST /tags/ ‚Äî criar tag (admin)
    - POST /tags/{tag_id}/empresas/{empresa_id} ‚Äî associar tag a empresa (admin)
    - DELETE /tags/{tag_id}/empresas/{empresa_id} ‚Äî remover associa√ß√£o (admin)

## Estado atual / O que foi feito

- Integra√ß√£o com SQLAlchemy e suporte a `DATABASE_URL` (Postgres) + fallback SQLite.
- Depend√™ncias de autoriza√ß√£o centralizadas (`get_current_user`, `require_admin`).
- Implementa√ß√£o de `Tag` com rela√ß√£o N:N (`empresa_tags`) e endpoints correspondentes.
- Alembic: `env.py` configurado; se necess√°rio foi usada a estrat√©gia `alembic stamp head` em dev local para evitar conflitos quando as tabelas j√° existiam.
- Testes b√°sicos (autentica√ß√£o + CRUD de empresas) adicionados e passando.

```
